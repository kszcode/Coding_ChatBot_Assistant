[
    {
        "content": "\nGenerate a sample user message file.",
        "role": "user"
    },
    {
        "content": "You are a Python coding assistant.\nThe USER will give you instructions to help write functions.\nYou may ask for clarification if needed, but otherwise you should only output Python code, if there are comments in the code then keep them.\nAdhere to PEP8. Provide explanations of the code only if the user asks for them.\n\nThe below code scratchpad may be provided by the user so you are aware of the script they are working on.\nNote, this information may be blank.\nEven if the below information is populated, it may not be relevant to the user's request.\nUse your best judgment to discern if the user is asking for you to modify the below code,\nor if the code is there for reference.\n\nCoding scratchpad:\nimport argparse\nimport json\nimport os\nimport re\nimport textwrap\nimport time\nfrom datetime import datetime\nfrom typing import Any, Union\nfrom typing import List\n\nimport openai\n\n\nclass AppState:\n    def __init__(self):\n        self.MODEL_NAME = \"gpt-4\"\n        self.MODEL_TEMPERATURE = 0.1\n        self.MODEL_MAX_TOKENS = 7500\n        self.USER_MESSAGE_FILE = 'user-message.md'\n        self.SYSTEM_MESSAGE_FILE = 'system-message.md'\n        self.SCRATCH_PAD_FILE = 'scratch-pad.py'\n        self.TOPIC_FOLDER = os.path.join(os.getcwd(), 'topics/1-change-topic-base-folder-python')\n        self.ALL_MESSAGES = list()\n        self.user_message = \"\"\n\n    def for_topic_get(self, file_path):\n        if os.path.exists(file_path):\n            return file_path\n        else:\n            return os.path.join(self.TOPIC_FOLDER, file_path)\n\n    def read_user_message_file(self):\n        file_path = self.for_topic_get(app_state.USER_MESSAGE_FILE)\n        content = read_file_content(file_path)\n        properties = {\n            'system_message_file': '',\n            'scratchpad_file': '',\n            'split_index': None,\n            'user_message': '',\n            'log_folder': os.path.dirname(file_path),\n        }\n\n        for line in content.splitlines():\n            if line.startswith('system_message_file:'):\n                properties['system_message_file'] = line.split(':', 1)[1].strip()\n            elif line.startswith('scratchpad_file:'):\n                properties['scratchpad_file'] = line.split(':', 1)[1].strip()\n            elif line.startswith('split_index:'):\n                properties['split_index'] = int(line.split(':', 1)[1].strip())\n            elif line.startswith('user_message:'):\n                properties['user_message'] = line.split(':', 1)[1].strip()\n            else:\n                properties['user_message'] += '\\n' + line\n\n        if properties['system_message_file'] is not None and properties['system_message_file'] != '':\n            self.SYSTEM_MESSAGE_FILE = properties['system_message_file']\n        if properties['scratchpad_file'] is not None and properties['scratchpad_file'] != '':\n            self.SCRATCH_PAD_FILE = properties['scratchpad_file']\n\n        self.user_message = properties['user_message']\n\n\napp_state = AppState()\n\n\n# Section:    logging for debug functions\n\ndef create_log_file(suffix: str) -> str:\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    log_dir = app_state.for_topic_get(\"./\")\n    if not os.path.exists(log_dir):\n        os.makedirs(log_dir)\n    log_file = os.path.join(log_dir, f\"{timestamp}{suffix}\")\n    return log_file\n\n\ndef save_request_as_human_readable_text(conversation, suffix):\n    log_file = create_log_file(suffix)\n    human_readable_text = \"\"\n    for message in conversation:\n        if 'role' in message and 'content' in message:\n            human_readable_text += f\"# {message['role'].upper()}:\\n{message['content']}\\n\\n\"\n        else:\n            print(f\"Skipping message due to missing 'role' or 'content': {message}\")\n    save_content_to_file(log_file, human_readable_text)\n\n\ndef save_response_as_human_readable_text(response, total_tokens, duration, suffix=\"\"):\n    log_file = create_log_file(suffix)\n    conversation: List[dict] = response[\"choices\"]\n    human_readable_text = f\"- Model      : {app_state.MODEL_NAME}\\n\"\n    human_readable_text += f\"- Temperature: {app_state.MODEL_TEMPERATURE}\\n\"\n    human_readable_text += f\"- Tokens     : {total_tokens}\\n\"\n    human_readable_text += f\"- Duration   : {duration}\\n\"\n    human_readable_text += \"\\n\\n\"\n    for message in conversation:\n        message = message[\"message\"]\n        if 'role' in message and 'content' in message:\n            human_readable_text += f\"# {message['role'].upper()}:\\n{message['content']}\\n\\n\"\n        else:\n            print(f\"Skipping message due to missing 'role' or 'content': {message}\")\n    save_content_to_file(log_file, human_readable_text)\n\n\ndef pretty_print_json(conversation: Any) -> Union[str, Any]:\n    try:\n        return json.dumps(conversation, indent=4, sort_keys=True)\n    except Exception:\n        return conversation\n\n\ndef save_json_log(conversation, suffix, pretty_print=True):\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    log_dir = \"log/openai\"\n    if not os.path.exists(log_dir):\n        os.makedirs(log_dir)\n    log_file = os.path.join(log_dir, f\"{timestamp}{suffix}.json\")\n    if pretty_print:\n        conversation = pretty_print_json(conversation)\n    save_content_to_file(log_file, str(conversation))\n\n\n# Section:     file operations\n\ndef save_content_to_file(filepath, content):\n    with open(filepath, 'w', encoding='utf-8') as outfile:\n        outfile.write(content)\n\n\ndef read_file_content(filepath):\n    try:\n        with open(filepath, 'r', encoding='utf-8', errors='ignore') as infile:\n            return infile.read()\n    except FileNotFoundError:\n        print(f\"File {filepath} not found.\")\n        exit(1)\n\n\n# Section:     API functions\n\ndef fetch_chatbot_response(conversation: List[dict]) -> dict:\n    return openai.ChatCompletion.create(\n        model=app_state.MODEL_NAME,\n        messages=conversation,\n        temperature=app_state.MODEL_TEMPERATURE,\n        # max_tokens=app_state.MODEL_MAX_TOKENS,\n    )\n\n\ndef handle_error(error, conversation):\n    print(f'\\n\\nError communicating with OpenAI: \"{error}\"')\n    if 'maximum context length' in str(error):\n        conversation.pop(0)\n        print('\\n\\n DEBUG: Trimming oldest message')\n        return True, conversation\n    return False, conversation\n\n\ndef perform_chatbot_conversation(conversation: List[dict]) -> tuple[Any, Any, float]:\n    max_retry: int = 7\n\n    # Save the conversation to a log file\n    save_json_log(conversation, f'_{app_state.MODEL_NAME}_request')\n    save_request_as_human_readable_text(conversation, f\"_{app_state.MODEL_NAME}_request.md\")\n\n    for retry in range(max_retry):\n        try:\n            start_time = time.time()\n            print(\"INFO: Processing...\")\n\n            response = fetch_chatbot_response(conversation)\n            text = response['choices'][0]['message']['content']\n            total_tokens = response['usage']['total_tokens']\n\n            end_time = time.time()\n            processing_time = end_time - start_time\n\n            save_json_log(response, f'_{total_tokens}_response', False)\n            save_response_as_human_readable_text(\n                response, total_tokens, processing_time,\n                f\"_{total_tokens}_response.md\",\n            )\n\n            return text, total_tokens, processing_time\n        except Exception as oops:\n            should_continue, conversation = handle_error(oops, conversation)\n            if not should_continue:\n                wait_time = 2 ** retry * 5\n                print(f'\\n\\nRetrying in {wait_time} seconds...')\n                time.sleep(wait_time)\n            else:\n                continue\n\n    print(f\"\\n\\nExiting due to excessive errors in API.\")\n    exit(1)\n\n\n###     MAIN LOOP\n\n\ndef multi_line_input():\n    print('\\n\\n\\nType END to save and exit.\\n[MULTI] USER:\\n')\n    lines = []\n    while True:\n        line = input()\n        if line == \"END\":\n            break\n        lines.append(line)\n    return \"\\n\".join(lines)\n\n\ndef print_chatbot_response(response, total_tokens, processing_time):\n    print('\\n\\n\\n\\nCHATBOT response:\\n')\n    formatted_lines = [textwrap.fill(line, width=120) for line in response.split('\\n')]\n    formatted_text = '\\n'.join(formatted_lines)\n    print(formatted_text)\n    print(f'\\n\\nINFO: {app_state.MODEL_NAME}: {total_tokens} tokens, {processing_time:.2f} seconds')\n\n\ndef read_scratchpad_file(file_path, split_index=None):\n    content = read_file_content(file_path)\n    if split_index is not None:\n        splits = re.split(r'\\n\\s*sfh-split-file-here\\s*\\n', content)\n        if split_index < len(splits):\n            return splits[split_index]\n        else:\n            print(f\"Error: split_index {split_index} is out of range.\")\n            exit(1)\n    else:\n        return content\n\n\ndef main():\n    # instantiate chatbot\n    openai.api_key = read_file_content('key_openai.txt').strip()\n\n    app_state.read_user_message_file()\n\n    print(f\"Current settings:\\n\"\n          f\"Model: {app_state.MODEL_NAME}\\n\"\n          f\"Temperature: {app_state.MODEL_TEMPERATURE}\")\n    print(\"Sample app usage: python chat.py --model gpt-3.5-turbo --temperature 0.2\")\n\n    print(f\"\\n\\nInput files:\\n\"\n          f\"Topic folder: {app_state.TOPIC_FOLDER}\\n\"\n          f\"User message: {app_state.USER_MESSAGE_FILE}\\n\"\n          f\"System message: {app_state.SYSTEM_MESSAGE_FILE}\\n\"\n          f\"Scratchpad: {app_state.SCRATCH_PAD_FILE}\")\n\n    print(f\"\\n\\nUser message is:\"\n          f\"\\n{read_file_content(app_state.user_message)}\"\n          f\"\\n\\n\")\n\n    # continue with composing conversation and response\n    app_state.ALL_MESSAGES.append({'role': 'user', 'content': app_state.user_message})\n    system_message = read_file_content(\n        app_state.for_topic_get(app_state.SYSTEM_MESSAGE_FILE),\n    ).replace('<<CODE>>', read_file_content(app_state.for_topic_get(app_state.SCRATCH_PAD_FILE)))\n    conversation = list()\n    conversation += app_state.ALL_MESSAGES\n    conversation.append({'role': 'system', 'content': system_message})\n\n    # generate a response\n    response, tokens, processing_time = perform_chatbot_conversation(conversation)\n\n    if tokens > app_state.MODEL_MAX_TOKENS:\n        app_state.ALL_MESSAGES.pop(0)\n\n    app_state.ALL_MESSAGES.append({'role': 'assistant', 'content': response})\n    print_chatbot_response(response, tokens, processing_time)\n\n\nif __name__ == '__main__':\n    main()\n\n",
        "role": "system"
    }
]